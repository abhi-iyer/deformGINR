{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from imports import *\n",
    "from utils import *\n",
    "from models import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "dataset = GraphDataset(dataset_dir=\"./data\")\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "model = GINR(input_dim=dataset.n_fourier, output_dim=dataset.target_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7861601114273071\n",
      "1.4737902879714966\n",
      "1.280212640762329\n",
      "1.1956686973571777\n",
      "1.1330339908599854\n",
      "1.0816857814788818\n",
      "1.0404603481292725\n",
      "0.9953533411026001\n",
      "0.9239322543144226\n",
      "0.8716025352478027\n",
      "0.8066348433494568\n",
      "0.7523773312568665\n",
      "0.7076318264007568\n",
      "0.6551966071128845\n",
      "0.6139400601387024\n",
      "0.5788874626159668\n",
      "0.5292903184890747\n",
      "0.4984230399131775\n",
      "0.46752774715423584\n",
      "0.4276343882083893\n",
      "0.4123784303665161\n",
      "0.38464340567588806\n",
      "0.3604182004928589\n",
      "0.3353862166404724\n",
      "0.32006633281707764\n",
      "0.2969149947166443\n",
      "0.28858819603919983\n",
      "0.27704593539237976\n",
      "0.24794726073741913\n",
      "0.2388116419315338\n",
      "0.22573012113571167\n",
      "0.22575363516807556\n",
      "0.21262559294700623\n",
      "0.21366606652736664\n",
      "0.21532396972179413\n",
      "0.20244237780570984\n",
      "0.19468745589256287\n",
      "0.18675781786441803\n",
      "0.18468044698238373\n",
      "0.18436570465564728\n",
      "0.18176774680614471\n",
      "0.16133709251880646\n",
      "0.18114842474460602\n",
      "0.181684210896492\n",
      "0.15678401291370392\n",
      "0.17154252529144287\n",
      "0.154585599899292\n",
      "0.17102603614330292\n",
      "0.16683824360370636\n",
      "0.16273179650306702\n",
      "0.16381916403770447\n",
      "0.16035877168178558\n",
      "0.15073435008525848\n",
      "0.15922677516937256\n",
      "0.13250544667243958\n",
      "0.1549321562051773\n",
      "0.14524908363819122\n",
      "0.15704120695590973\n",
      "0.1374618113040924\n",
      "0.1328202337026596\n",
      "0.15173862874507904\n",
      "0.15404392778873444\n",
      "0.15030112862586975\n",
      "0.1521030217409134\n",
      "0.14061346650123596\n",
      "0.14319559931755066\n",
      "0.1498158872127533\n",
      "0.13917861878871918\n",
      "0.1310754418373108\n",
      "0.12529359757900238\n",
      "0.14479205012321472\n",
      "0.13990651071071625\n",
      "0.12755249440670013\n",
      "0.1396687775850296\n",
      "0.12188658118247986\n",
      "0.14059963822364807\n",
      "0.14272372424602509\n",
      "0.12685810029506683\n",
      "0.13299894332885742\n",
      "0.14117658138275146\n",
      "0.13773572444915771\n",
      "0.13360363245010376\n",
      "0.1313302218914032\n",
      "0.13400331139564514\n",
      "0.12474662810564041\n",
      "0.13182461261749268\n",
      "0.14118725061416626\n",
      "0.12585702538490295\n",
      "0.13204531371593475\n",
      "0.11961720883846283\n",
      "0.12205534428358078\n",
      "0.13092978298664093\n",
      "0.12961916625499725\n",
      "0.1342397779226303\n",
      "0.12264162302017212\n",
      "0.12387950718402863\n",
      "0.14605651795864105\n",
      "0.13731695711612701\n",
      "0.13970829546451569\n",
      "0.14364080131053925\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "train_losses = []\n",
    "\n",
    "for _ in range(num_epochs):\n",
    "    epoch_losses = []\n",
    "\n",
    "    for batch in train_loader:\n",
    "        inputs, targets, _ = batch[\"inputs\"], batch[\"targets\"], batch[\"index\"]\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        bs = inputs.shape[0]\n",
    "\n",
    "        inputs.requires_grad_()\n",
    "\n",
    "        pred = model.forward(inputs)  \n",
    "\n",
    "        loss = loss_fn(torch.permute(pred, (0, 2, 1)), targets.reshape(bs, -1).long())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "\n",
    "    train_losses.append(np.mean(epoch_losses))\n",
    "\n",
    "    print(train_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ginr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b3c2da8d5765b3404357eb9d275f83d59d95b3f7675432adf388d43dc3d5022e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
